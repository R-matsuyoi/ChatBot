DeepSeek-R1是深度求索（DeepSeek）于2025年1月20日发布的人工智能大型语言模型，专门适用于数学、编码和逻辑等任务，性能对标OpenAI o1[1]。

开发
Deepseek R1 Lite
开发者	深度求索
首次发布	2024年11月20日，​3个月前
源代码库	
github.com/deepseek-ai/DeepSeek-R1
编辑维基数据链接
前任	DeepSeek V2.5
继任	Deepseek-V3
类型	
大型语言模型
基于转换器的生成式预训练模型
基础模型
许可协议	专有软件
网站	www.deepseek.com
DeepSeek-R1-Lite是深度求索于2024年11月20日发布的人工智能大型语言模型，是深度求索第一个推理模型。专门适用于数学、编码和逻辑等任务，性能对标OpenAI o1，DeepSeek-R1-Lite是Deepseek R1的预览版。[2]DeepSeek称该模型用了强化学习训练，并为用户展现了 o1 没有公开的完整思考过程。而该模型关键特点就是便宜，与OpenAI o1的价格相差极大。Deepseek R1 Lite在回答问题前会花更多时间思考，因此准确度会增强。Deepseek的测试结果表明，在数学竞赛上的得分与测验所允许思考的长度紧密相关，而模型思维炼长度增加展现了更高的效率。[2]

Deepseek-R1-Lite在数学、代码和复杂逻辑推理上，获得媲美 o1-preview 的推理效果。在美国数学邀请赛中DeepSeek 称，该模型在美国邀请数学考试和 MATH 等既定基准上的表现超过了 OpenAI o1 Preview的水平，在国际数学奥林匹克正确率达到83%，它还在Codeforces编程竞赛中优于89%的参赛者，但在GPQA Diamond，LiveCodeBench和自然语言解迷中较为逊色。[3]

DeepSeek-R1的论文中没有公布其训练成本等细节。[4]不过此前的论文中，DeepSeek透露其训练使用的是英伟达因为美国出口管制而针对中国市场特供的低配版GPU H800，训练成本为557.6万美元，远低于类似西方公司的闭源模型。[1][5][6]外界预估R1的训练成本也不会比DeepSeek-V3高多少，或在600万美元上下。[7]

使用
DeepSeek-R1使用MIT协议开源，意味着任何人都可以自由使用该模型，包括商业用途。用户可以在DeepSeek官方网站和App使用官方提供的服务。

DeepSeek-R1上线时提供的API服务定价为每百万输入tokens 1元人民币（缓存命中）/4元（缓存未命中），每百万输出tokens 16元，输出API价格仅仅只有OpenAI o1的3%。[8]

外界反应
1月27日，DeepSeek超越ChatGPT，登顶苹果App Store美国区免费APP下载排行榜。[9]

DeepSeek-R1爆火，引发全球投资者大量抛售人工智能相关股票。1月27日，英伟达美股股价下跌近17%，单日市值蒸发5890亿美元，为美国股市历史上最大。[10][11]

DeepSeek-R1发布后不久，Meta首席执行官马克·扎克伯格就宣布，Meta计划在2025年投入超600亿美元，加大对人工智能的投入。[7]据媒体1月27日报道，Meta成立了四个研究小组，专门研究DeepSeek的模型。[12]其中两个小组研究其开发者如何降低训练和运行DeepSeek的成本，第三个小组研究训练模型可能使用了哪些数据，第四个小组研究基于DeepSeek模型属性重构其LLaMA模型的新技术。[13]

OpenAI表示，其有证据表明DeepSeek使用OpenAI的专有模型来训练自己的开源模型，这违反了OpenAI的服务条款。[14]

现状与替代方案
由于用户量激增，DeepSeek R1曾面临服务器频繁繁忙问题，主要归因可能有多种，包括算力需求、带宽限制及网络攻击。用户可通过本地部署（如Ollama工具）、调用API或使用第三方平台（如秘塔AI搜索、腾讯元宝、超算互联网、Poe、问小白、Coze、纳米搜索、英伟达NIM微服务、微软Azure、亚马逊AWS等）缓解访问压力[15][需要较佳来源]。